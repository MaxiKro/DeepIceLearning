# # results #
# feedforward neural net 5160-1024-512-2, relu activations. trained on 75% of 10501 datasets. tested on 25%.
# 
# Epoch 50/50
# 7875/7875 [==============================] - 3s - loss: 0.6672 - acc: 0.6000 
# 
# [INFO] evaluating on testing set...
# 2432/2626 [==========================>...] - ETA: 0s[INFO] loss=0.6787, accuracy: 56.5499%

# RESULTS GridSearch
"""
Best: 0.626794 using {'optimizer': 'Adagrad'}
0.549841 (0.011489) with: {'optimizer': 'SGD'}
0.575873 (0.012758) with: {'optimizer': 'RMSprop'}
0.626794 (0.008722) with: {'optimizer': 'Adagrad'}
0.568762 (0.015531) with: {'optimizer': 'Adadelta'}
0.597333 (0.008159) with: {'optimizer': 'Adam'}
0.599746 (0.001823) with: {'optimizer': 'Adamax'}
0.586413 (0.028847) with: {'optimizer': 'Nadam'}


"""
#bis jetzt mit vollem 000000-000999 first50 datensatz. jetzt mit gefiltert: |theta-90|>15
#parallel search anzahl neutrons tunen
"""
[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 139.3min finished
[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 169.1min finished
Fitting 3 folds for each of 20 candidates, totalling 60 fits
[INFO] randomized search took 8472.78 seconds
Fitting 3 folds for each of 20 candidates, totalling 60 fits
Best: 0.657148 using {'neurons1': 1824, 'neurons2': 612}
"""

---
trying out what results the above gives:
---
#tuned: act f's, layer size, optimizer. now trying to train it the normal way and see what results i get. splitted train and test data set 75:25. today is the 12.july

Training model
fitting...
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 1824)              9413664
_________________________________________________________________
dense_2 (Dense)              (None, 612)               1116900
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1226
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0
=================================================================
Total params: 10,531,790
Trainable params: 10,531,790
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/10
5673/5673 [==============================] - 24s - loss: 0.9917 - acc: 0.6200
Epoch 2/10
5673/5673 [==============================] - 23s - loss: 0.4313 - acc: 0.8086
Epoch 3/10
5673/5673 [==============================] - 24s - loss: 0.2293 - acc: 0.9159
Epoch 4/10
5673/5673 [==============================] - 23s - loss: 0.1112 - acc: 0.9646
Epoch 5/10
5673/5673 [==============================] - 23s - loss: 0.0531 - acc: 0.9877
Epoch 6/10
5673/5673 [==============================] - 23s - loss: 0.0282 - acc: 0.9940
Epoch 7/10
5673/5673 [==============================] - 23s - loss: 0.0173 - acc: 0.9972
Epoch 8/10
5673/5673 [==============================] - 23s - loss: 0.0120 - acc: 0.9984
Epoch 9/10
5673/5673 [==============================] - 24s - loss: 0.0087 - acc: 0.9995
Epoch 10/10
5673/5673 [==============================] - 24s - loss: 0.0063 - acc: 0.9996
[INFO] evaluating on testing set...
1892/1892 [==============================] - 1s
[INFO] loss=1.1165, accuracy: 70.4545%
time to fit: 243.911514997

---
now with direct validation
---

Training model
fitting...
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 1824)              9413664
_________________________________________________________________
dense_2 (Dense)              (None, 612)               1116900
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1226
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0
=================================================================
Total params: 10,531,790
Trainable params: 10,531,790
Non-trainable params: 0
_________________________________________________________________
None
Train on 5673 samples, validate on 1892 samples
Epoch 1/20
5673/5673 [==============================] - 25s - loss: 0.9676 - acc: 0.5769 - val_loss: 0.6280 - val_acc: 0.6469
Epoch 2/20
5673/5673 [==============================] - 25s - loss: 0.4717 - acc: 0.7835 - val_loss: 0.6965 - val_acc: 0.6654
Epoch 3/20
5673/5673 [==============================] - 25s - loss: 0.2482 - acc: 0.9052 - val_loss: 0.7276 - val_acc: 0.7014
Epoch 4/20
5673/5673 [==============================] - 25s - loss: 0.1104 - acc: 0.9670 - val_loss: 0.8001 - val_acc: 0.6987
Epoch 5/20
5673/5673 [==============================] - 25s - loss: 0.0526 - acc: 0.9900 - val_loss: 0.9039 - val_acc: 0.6929
Epoch 6/20
5673/5673 [==============================] - 26s - loss: 0.0290 - acc: 0.9945 - val_loss: 0.9574 - val_acc: 0.6982
Epoch 7/20
5673/5673 [==============================] - 26s - loss: 0.0167 - acc: 0.9984 - val_loss: 1.0209 - val_acc: 0.6929
Epoch 8/20
5673/5673 [==============================] - 26s - loss: 0.0111 - acc: 0.9995 - val_loss: 1.0719 - val_acc: 0.6903
Epoch 9/20
5673/5673 [==============================] - 26s - loss: 0.0082 - acc: 0.9996 - val_loss: 1.1185 - val_acc: 0.6866
Epoch 10/20
5673/5673 [==============================] - 25s - loss: 0.0066 - acc: 0.9991 - val_loss: 1.1454 - val_acc: 0.6908
Epoch 11/20
5673/5673 [==============================] - 25s - loss: 0.0050 - acc: 1.0000 - val_loss: 1.1760 - val_acc: 0.6887
Epoch 12/20
5673/5673 [==============================] - 25s - loss: 0.0040 - acc: 1.0000 - val_loss: 1.2027 - val_acc: 0.6887
Epoch 13/20
5673/5673 [==============================] - 25s - loss: 0.0033 - acc: 1.0000 - val_loss: 1.2252 - val_acc: 0.6919
Epoch 14/20
5673/5673 [==============================] - 25s - loss: 0.0029 - acc: 1.0000 - val_loss: 1.2465 - val_acc: 0.6908
Epoch 15/20
5673/5673 [==============================] - 25s - loss: 0.0025 - acc: 1.0000 - val_loss: 1.2655 - val_acc: 0.6919
Epoch 16/20
5673/5673 [==============================] - 25s - loss: 0.0022 - acc: 1.0000 - val_loss: 1.2826 - val_acc: 0.6919
Epoch 17/20
5673/5673 [==============================] - 25s - loss: 0.0020 - acc: 1.0000 - val_loss: 1.2975 - val_acc: 0.6929
Epoch 18/20
5673/5673 [==============================] - 25s - loss: 0.0019 - acc: 1.0000 - val_loss: 1.3139 - val_acc: 0.6913
Epoch 19/20
5673/5673 [==============================] - 25s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3280 - val_acc: 0.6924
Epoch 20/20
5673/5673 [==============================] - 25s - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3414 - val_acc: 0.6919



----
11/07 09:29:57
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 1024)              5284864   
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1026      
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0         
=================================================================
Total params: 5,810,690
Trainable params: 5,810,690
Non-trainable params: 0
_________________________________________________________________
None
tuning with:  {'activations': [('relu', 'softmax'), ('relu', 'softplus'), ('relu', 'softsign'), ('relu', 'relu'), ('relu', 'tanh'), ('relu', 'sigmoid'), ('relu', 'hard_sigmoid'), ('relu', 'linear'), ('softmax', 'relu'), ('softplus', 'relu'), ('softsign', 'relu'), ('relu', 'relu'), ('tanh', 'relu'), ('sigmoid', 'relu'), ('hard_sigmoid', 'relu'), ('linear', 'relu')]}
[INFO] randomized search took 11199.55 seconds
Best: 0.679841 using {'activations': ('relu', 'softplus')}
0.662393 (0.012443) with: {'activations': ('relu', 'softmax')}
0.679841 (0.013616) with: {'activations': ('relu', 'softplus')}
0.668738 (0.010981) with: {'activations': ('relu', 'softsign')}
0.670324 (0.004056) with: {'activations': ('relu', 'relu')}
0.668209 (0.006067) with: {'activations': ('relu', 'tanh')}
0.675347 (0.003455) with: {'activations': ('relu', 'sigmoid')}
0.676272 (0.003189) with: {'activations': ('relu', 'hard_sigmoid')}
0.664243 (0.006773) with: {'activations': ('relu', 'linear')}
0.606081 (0.012470) with: {'activations': ('softmax', 'relu')}
0.527958 (0.057065) with: {'activations': ('softplus', 'relu')}
0.631064 (0.007903) with: {'activations': ('softsign', 'relu')}
0.669663 (0.011315) with: {'activations': ('relu', 'relu')}
0.639128 (0.006809) with: {'activations': ('tanh', 'relu')}
0.436880 (0.007344) with: {'activations': ('sigmoid', 'relu')}
0.563120 (0.007344) with: {'activations': ('hard_sigmoid', 'relu')}
0.624983 (0.009596) with: {'activations': ('linear', 'relu')}
time to fit: 11199.551615


----
12/07 09:17:25
with GridSearchCV
tuning with:  {'inits': [('uniform', 'uniform'), ('uniform', 'normal'), ('normal', 'uniform'), ('normal', 'normal')]}
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 1824)              9413664   
_________________________________________________________________
dense_2 (Dense)              (None, 612)               1116900   
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1226      
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0         
=================================================================
Total params: 10,531,790
Trainable params: 10,531,790
Non-trainable params: 0
_________________________________________________________________
None
[INFO] randomized search took 5621.95 seconds
Best: 0.683278 using {'inits': ('uniform', 'uniform')}
0.683278 (0.005897) with: {'inits': ('uniform', 'uniform')}
0.681295 (0.005123) with: {'inits': ('uniform', 'normal')}
0.671778 (0.009574) with: {'inits': ('normal', 'uniform')}
0.656312 (0.006078) with: {'inits': ('normal', 'normal')}





----
13/07 10:20:00
tuning modelwith RandomSearchCV
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 1824)              9413664   
_________________________________________________________________
dropout_1 (Dropout)          (None, 1824)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 612)               1116900   
_________________________________________________________________
dropout_2 (Dropout)          (None, 612)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1226      
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0         
=================================================================
Total params: 10,531,790
Trainable params: 10,531,790
Non-trainable params: 0
_________________________________________________________________
None
tuning with:  {'weight_constraints': [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)], 'dropout_rates': [(0.0, 0.0), (0.1, 0.1), (0.2, 0.2), (0.3, 0.3), (0.4, 0.4), (0.5, 0.5), (0.6, 0.6), (0.7, 0.7), (0.8, 0.8), (0.9, 0.9)]}
tuning randomly with RandomSearchCV
Fitting 3 folds for each of 30 candidates, totalling 90 fits
Best: 0.690681 using {'weight_constraints': (3, 3), 'dropout_rates': (0.4, 0.4)}
0.686980 (0.007095) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.3, 0.3)}
0.681956 (0.006644) with: {'weight_constraints': (5, 5), 'dropout_rates': (0.3, 0.3)}
0.683146 (0.002815) with: {'weight_constraints': (1, 1), 'dropout_rates': (0.2, 0.2)}
0.678387 (0.010751) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.9, 0.9)}
0.682617 (0.014319) with: {'weight_constraints': (5, 5), 'dropout_rates': (0.2, 0.2)}
0.686186 (0.007176) with: {'weight_constraints': (1, 1), 'dropout_rates': (0.4, 0.4)}
0.686715 (0.002858) with: {'weight_constraints': (2, 2), 'dropout_rates': (0.6, 0.6)}
0.676537 (0.015056) with: {'weight_constraints': (3, 3), 'dropout_rates': (0.1, 0.1)}
0.684468 (0.006059) with: {'weight_constraints': (2, 2), 'dropout_rates': (0.5, 0.5)}
0.683675 (0.007240) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.5, 0.5)}
0.683807 (0.013392) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.7, 0.7)}
0.680635 (0.007693) with: {'weight_constraints': (3, 3), 'dropout_rates': (0.8, 0.8)}
0.684204 (0.005690) with: {'weight_constraints': (1, 1), 'dropout_rates': (0.5, 0.5)}
0.685790 (0.006633) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.0, 0.0)}
0.686186 (0.009432) with: {'weight_constraints': (2, 2), 'dropout_rates': (0.7, 0.7)}
0.690681 (0.005399) with: {'weight_constraints': (3, 3), 'dropout_rates': (0.4, 0.4)}
0.688169 (0.004819) with: {'weight_constraints': (1, 1), 'dropout_rates': (0.6, 0.6)}
0.683543 (0.006199) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.4, 0.4)}
0.684732 (0.006733) with: {'weight_constraints': (3, 3), 'dropout_rates': (0.3, 0.3)}
0.678784 (0.014624) with: {'weight_constraints': (1, 1), 'dropout_rates': (0.3, 0.3)}
0.674686 (0.011038) with: {'weight_constraints': (3, 3), 'dropout_rates': (0.2, 0.2)}
0.683675 (0.006106) with: {'weight_constraints': (5, 5), 'dropout_rates': (0.6, 0.6)}
0.685525 (0.003714) with: {'weight_constraints': (3, 3), 'dropout_rates': (0.0, 0.0)}
0.687640 (0.005111) with: {'weight_constraints': (5, 5), 'dropout_rates': (0.4, 0.4)}
0.683939 (0.004237) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.6, 0.6)}
0.673496 (0.018359) with: {'weight_constraints': (5, 5), 'dropout_rates': (0.9, 0.9)}
0.687244 (0.009235) with: {'weight_constraints': (2, 2), 'dropout_rates': (0.1, 0.1)}
0.686715 (0.008740) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.1, 0.1)}
0.679048 (0.002099) with: {'weight_constraints': (4, 4), 'dropout_rates': (0.2, 0.2)}
0.688169 (0.008902) with: {'weight_constraints': (5, 5), 'dropout_rates': (0.1, 0.1)}

Training model
fitting...
with params {'weight_constraints': (3, 3), 'dropout_rates': (0.6, 0.6)}
(0.6, 0.6) (3, 3)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 1824)              9413664
_________________________________________________________________
dropout_1 (Dropout)          (None, 1824)              0
_________________________________________________________________
dense_2 (Dense)              (None, 612)               1116900
_________________________________________________________________
dropout_2 (Dropout)          (None, 612)               0
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1226
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0
=================================================================
Total params: 10,531,790
Trainable params: 10,531,790
Non-trainable params: 0
_________________________________________________________________
None
Train on 5673 samples, validate on 1892 samples
Epoch 1/20
5673/5673 [==============================] - 31s - loss: 1.0831 - acc: 0.5745 - val_loss: 0.6051 - val_acc: 0.6845
Epoch 2/20
5673/5673 [==============================] - 31s - loss: 0.6130 - acc: 0.7003 - val_loss: 0.6653 - val_acc: 0.6660
Epoch 3/20
5673/5673 [==============================] - 31s - loss: 0.4498 - acc: 0.7973 - val_loss: 0.6226 - val_acc: 0.7098
Epoch 4/20
5673/5673 [==============================] - 31s - loss: 0.3462 - acc: 0.8549 - val_loss: 0.6572 - val_acc: 0.7135
Epoch 5/20
5673/5673 [==============================] - 31s - loss: 0.2688 - acc: 0.8897 - val_loss: 0.7009 - val_acc: 0.7040
Epoch 6/20
5673/5673 [==============================] - 31s - loss: 0.2087 - acc: 0.9163 - val_loss: 0.7499 - val_acc: 0.7051
Epoch 7/20
5673/5673 [==============================] - 31s - loss: 0.1538 - acc: 0.9409 - val_loss: 0.8272 - val_acc: 0.6850
Epoch 8/20
5673/5673 [==============================] - 31s - loss: 0.1183 - acc: 0.9540 - val_loss: 0.8618 - val_acc: 0.7014
Epoch 9/20
5673/5673 [==============================] - 30s - loss: 0.0951 - acc: 0.9665 - val_loss: 0.9096 - val_acc: 0.7040
Epoch 10/20
5673/5673 [==============================] - 31s - loss: 0.0797 - acc: 0.9695 - val_loss: 0.9606 - val_acc: 0.6987
Epoch 11/20
5673/5673 [==============================] - 31s - loss: 0.0619 - acc: 0.9796 - val_loss: 1.0095 - val_acc: 0.7014
Epoch 12/20
5673/5673 [==============================] - 31s - loss: 0.0540 - acc: 0.9818 - val_loss: 1.0489 - val_acc: 0.6987
Epoch 13/20
5673/5673 [==============================] - 31s - loss: 0.0429 - acc: 0.9868 - val_loss: 1.0882 - val_acc: 0.6993
Epoch 14/20
5673/5673 [==============================] - 31s - loss: 0.0369 - acc: 0.9878 - val_loss: 1.1198 - val_acc: 0.6993
Epoch 15/20
5673/5673 [==============================] - 31s - loss: 0.0356 - acc: 0.9885 - val_loss: 1.1571 - val_acc: 0.6971
Epoch 16/20
5673/5673 [==============================] - 31s - loss: 0.0286 - acc: 0.9919 - val_loss: 1.1947 - val_acc: 0.7014
Epoch 17/20
5673/5673 [==============================] - 31s - loss: 0.0280 - acc: 0.9908 - val_loss: 1.2200 - val_acc: 0.6977
Epoch 18/20
5673/5673 [==============================] - 31s - loss: 0.0289 - acc: 0.9921 - val_loss: 1.2478 - val_acc: 0.6966
Epoch 19/20
5673/5673 [==============================] - 30s - loss: 0.0242 - acc: 0.9922 - val_loss: 1.2678 - val_acc: 0.6903
Epoch 20/20
5673/5673 [==============================] - 31s - loss: 0.0219 - acc: 0.9931 - val_loss: 1.2958 - val_acc: 0.6855