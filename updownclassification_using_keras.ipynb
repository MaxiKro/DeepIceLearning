{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pulses_file = \"./data/inicedstpulses_nugen11069_first50i3files.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take care with that dataset: entry (1106900050, 1612) appeares to be available twice in MCPrimary table... delete it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_geo_data(geo_file):\n",
    "    #return the contents of the geo file as\n",
    "    #dictionary mapping (omkey[0],omkey[1]) -> (posx,posy,poz)\n",
    "    import csv\n",
    "    ret = {}\n",
    "    with open(geo_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in reader:\n",
    "            key = tuple(map(int, line[0:2]))\n",
    "            val = tuple(map(float, line[2:5]))\n",
    "            ret[key] = val\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_raw_xlist(geo=None):\n",
    "    \"\"\"\n",
    "    returns a two tuple:\n",
    "    1) a np array of lenght #DOMS filled with zeroes. copy this for every dataset later on\n",
    "    2) a dictionary mapping (string, om) to an index (something like $index = (string-1)*60+(om-1)$)\n",
    "    \n",
    "    geo is the object created by load_geo_data. \n",
    "    if no geo specified use standard values: string in [1,86], om in [1,60]\n",
    "    \"\"\"\n",
    "    if geo:\n",
    "        dom_to_index = {}\n",
    "        raw_xlist = np.zeros((len(geo)), dtype=np.float32)\n",
    "        for i, dom in enumerate(geo.keys()):\n",
    "            raw_xlist[i] = 0.0 #this will also be the value used for non hit DOM's\n",
    "            dom_to_index[dom] = i\n",
    "        return raw_xlist, dom_to_index\n",
    "    else: #no geo file specified, use standard values: string in [1,86], om in [1,60]\n",
    "        dom_to_index = {}\n",
    "        for i, (string, om) in enumerate(itertools.product(range(1,87), range(1,61))):\n",
    "            dom_to_index[(string, om)] = i\n",
    "        raw_xlist = np.zeros((86*60), dtype=np.float32)\n",
    "        return raw_xlist, dom_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pulses_data(pulses_file, geo_file=None):\n",
    "    #returns data from dstpulses. Returns only the first puls from each dom in the list.\n",
    "    #splits per frames\n",
    "    \"\"\"Return a tuple containing ``(data,  labels)``.\n",
    "    \n",
    "    In particular, ``data`` is a list containing a dozen thousand\n",
    "    lists ``[chargedom1,chargedom2,...]``.  the index of the dom is simply a walkthrough through \n",
    "    every (string, om)-pair\n",
    "    \n",
    "    ``labels`` is the\n",
    "    corresponding information about being a north or south-coming particle,\n",
    "    i.e., 0 for above (south) and 1 for below (north). this is chosen on the\n",
    "    zenith angle of MCTree's most energetic primary (1 for > or 0 for < 90deg). it is made categorical:\n",
    "    [[0,1],[0,1],[1,0],...] for [down, down, up, ...]\n",
    "\n",
    "    For DOMs that include multiple pulses, -the earliest time is used for simplification- sum of charge is used.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_pos(dom_to_index, string, om):\n",
    "        if (string, om) not in dom_to_index:\n",
    "            return -1\n",
    "        return dom_to_index[(string, om)]\n",
    "\n",
    "    def normalize_time(time_list):\n",
    "        maxtime, mintime = 0, float(\"inf\")\n",
    "        for t in time_list[:,0]:\n",
    "            maxtime = max(maxtime, t)\n",
    "            mintime = min(mintime, t)\n",
    "        timespan = maxtime - mintime\n",
    "        time_list[:,0] -= mintime\n",
    "        time_list[:,0] /= timespan\n",
    "    def normalize_charge(charge_list):\n",
    "        maxcharge, mincharge = 0, float(\"inf\")\n",
    "        for c in charge_list:\n",
    "            maxcharge = max(maxcharge, c)\n",
    "            mincharge = min(mincharge, c)\n",
    "        span = maxcharge - mincharge\n",
    "        charge_list -= mincharge\n",
    "        charge_list /= span\n",
    "\n",
    "    raw_xlist, dom_to_index = produce_raw_xlist()\n",
    "\n",
    "    h5file = tables.open_file(pulses_file)\n",
    "    dst = h5file.root.InIceDSTPulses.cols\n",
    "    prim = h5file.root.MCPrimary.cols\n",
    "\n",
    "    data = []   #total charge (summed over pulses) per dom and per frame. 2d numpy array\n",
    "    labels = [] #up or down, categorical [[0,1],[0,1],[1,0],...]. 2d numpy array\n",
    "    prev_frame = (dst.Run[0],dst.Event[0])\n",
    "    prev_dom = (-1,-1)\n",
    "    x_list = np.copy(raw_xlist)\n",
    "    count = 0\n",
    "    x_i = 0\n",
    "\n",
    "    for zenith in prim.zenith:\n",
    "        labels.append(1 if zenith > 1.5707963268 else 0) #1==down, 0==up\n",
    "    labels = np_utils.to_categorical(labels)\n",
    "\n",
    "    total_rows = len(dst.Run)\n",
    "    i=0\n",
    "    for run, event, string, om, time, charge in zip(dst.Run, dst.Event, dst.string, dst.om, \\\n",
    "                                                    dst.time, dst.charge):\n",
    "        if (run, event) != prev_frame: #next frame is coming, so push this out as charges list\n",
    "            normalize_charge(x_list)\n",
    "            data.append(x_list)\n",
    "            x_list = np.copy(raw_xlist)\n",
    "            count += 1\n",
    "            prev_frame = (run,event)\n",
    "\n",
    "        if (string, om) == prev_dom: #already saw that dom (it has multiple pulses)\n",
    "            x_list[dom_index] += charge\n",
    "        else: #pulse for new dom\n",
    "            dom_index = get_pos(dom_to_index, string, om)\n",
    "            if dom_index == -1: #this must be one of those om=61,62,63,64 (i.e. icetop). we're not interested in them\n",
    "                continue\n",
    "            x_list[dom_index] = charge\n",
    "            prev_dom = (string, om)\n",
    "            \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 10**6 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, total_rows))\n",
    "        i += 1\n",
    "\n",
    "    #add the last frame manually\n",
    "    normalize_charge(x_list)\n",
    "    data.append(x_list)\n",
    "\n",
    "    return (np.array(data), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000000/43287699\n",
      "[INFO] processed 2000000/43287699\n",
      "[INFO] processed 3000000/43287699\n",
      "[INFO] processed 4000000/43287699\n",
      "[INFO] processed 5000000/43287699\n",
      "[INFO] processed 6000000/43287699\n",
      "[INFO] processed 7000000/43287699\n",
      "[INFO] processed 8000000/43287699\n",
      "[INFO] processed 9000000/43287699\n",
      "[INFO] processed 10000000/43287699\n",
      "[INFO] processed 11000000/43287699\n",
      "[INFO] processed 12000000/43287699\n",
      "[INFO] processed 13000000/43287699\n",
      "[INFO] processed 14000000/43287699\n",
      "[INFO] processed 15000000/43287699\n",
      "[INFO] processed 16000000/43287699\n",
      "[INFO] processed 17000000/43287699\n",
      "[INFO] processed 18000000/43287699\n",
      "[INFO] processed 19000000/43287699\n",
      "[INFO] processed 20000000/43287699\n",
      "[INFO] processed 21000000/43287699\n",
      "[INFO] processed 22000000/43287699\n",
      "[INFO] processed 23000000/43287699\n",
      "[INFO] processed 24000000/43287699\n",
      "[INFO] processed 25000000/43287699\n",
      "[INFO] processed 26000000/43287699\n",
      "[INFO] processed 27000000/43287699\n",
      "[INFO] processed 28000000/43287699\n",
      "[INFO] processed 29000000/43287699\n",
      "[INFO] processed 30000000/43287699\n",
      "[INFO] processed 31000000/43287699\n",
      "[INFO] processed 32000000/43287699\n",
      "[INFO] processed 33000000/43287699\n",
      "[INFO] processed 34000000/43287699\n",
      "[INFO] processed 35000000/43287699\n",
      "[INFO] processed 36000000/43287699\n",
      "[INFO] processed 37000000/43287699\n",
      "[INFO] processed 38000000/43287699\n",
      "[INFO] processed 39000000/43287699\n",
      "[INFO] processed 40000000/43287699\n",
      "[INFO] processed 41000000/43287699\n",
      "[INFO] processed 42000000/43287699\n",
      "[INFO] processed 43000000/43287699\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_pulses_data(pulses_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5=tables.open_file(pulses_file)\n",
    "mcp=h5.root.MCPrimary.cols\n",
    "index_to_remove = -1\n",
    "for i, (run,event) in enumerate(zip(mcp.Run, mcp.Event)):\n",
    "    if (run, event) == (1106900050, 1612):\n",
    "        index_to_remove = i\n",
    "        break\n",
    "if len(labels) > len(data): #just to be sure...\n",
    "    labels = np.delete(labels, index_to_remove, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(trainData, testData, trainLabels, testLabels) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=5160, kernel_initializer=\"uniform\",\n",
    "\tactivation=\"relu\"))\n",
    "model.add(Dense(512, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6918 - acc: 0.5342     \n",
      "Epoch 2/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6902 - acc: 0.5458     \n",
      "Epoch 3/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6894 - acc: 0.5450     \n",
      "Epoch 4/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6889 - acc: 0.5450     \n",
      "Epoch 5/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6884 - acc: 0.5453     \n",
      "Epoch 6/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6879 - acc: 0.5450     \n",
      "Epoch 7/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6875 - acc: 0.5453     \n",
      "Epoch 8/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6870 - acc: 0.5464     \n",
      "Epoch 9/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6865 - acc: 0.5468     \n",
      "Epoch 10/50\n",
      "7875/7875 [==============================] - 4s - loss: 0.6861 - acc: 0.5468     \n",
      "Epoch 11/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6856 - acc: 0.5472     \n",
      "Epoch 12/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6852 - acc: 0.5479     \n",
      "Epoch 13/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6847 - acc: 0.5484     \n",
      "Epoch 14/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6843 - acc: 0.5495     \n",
      "Epoch 15/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6839 - acc: 0.5521     \n",
      "Epoch 16/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6834 - acc: 0.5517     \n",
      "Epoch 17/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6830 - acc: 0.5539     \n",
      "Epoch 18/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6825 - acc: 0.5557     \n",
      "Epoch 19/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6821 - acc: 0.5567     \n",
      "Epoch 20/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6817 - acc: 0.5582     \n",
      "Epoch 21/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6812 - acc: 0.5618     \n",
      "Epoch 22/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6808 - acc: 0.5624     \n",
      "Epoch 23/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6803 - acc: 0.5693     \n",
      "Epoch 24/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6799 - acc: 0.5685     \n",
      "Epoch 25/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6795 - acc: 0.5685     \n",
      "Epoch 26/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6790 - acc: 0.5716     \n",
      "Epoch 27/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6786 - acc: 0.5745     \n",
      "Epoch 28/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6781 - acc: 0.5747     \n",
      "Epoch 29/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6777 - acc: 0.5761     \n",
      "Epoch 30/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6772 - acc: 0.5771     \n",
      "Epoch 31/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6767 - acc: 0.5812     \n",
      "Epoch 32/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6763 - acc: 0.5799     \n",
      "Epoch 33/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6758 - acc: 0.5816     \n",
      "Epoch 34/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6753 - acc: 0.5825     \n",
      "Epoch 35/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6749 - acc: 0.5850     \n",
      "Epoch 36/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6744 - acc: 0.5876     \n",
      "Epoch 37/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6739 - acc: 0.5882     \n",
      "Epoch 38/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6734 - acc: 0.5901     \n",
      "Epoch 39/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6729 - acc: 0.5876     \n",
      "Epoch 40/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6724 - acc: 0.5924     \n",
      "Epoch 41/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6719 - acc: 0.5928     \n",
      "Epoch 42/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6714 - acc: 0.5928     \n",
      "Epoch 43/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6709 - acc: 0.5948     \n",
      "Epoch 44/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6704 - acc: 0.5954     \n",
      "Epoch 45/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6699 - acc: 0.5959     \n",
      "Epoch 46/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6694 - acc: 0.5956     \n",
      "Epoch 47/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6688 - acc: 0.5972     \n",
      "Epoch 48/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6683 - acc: 0.5977     \n",
      "Epoch 49/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6677 - acc: 0.6006     \n",
      "Epoch 50/50\n",
      "7875/7875 [==============================] - 3s - loss: 0.6672 - acc: 0.6000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f8aa810>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.fit(trainData, trainLabels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating on testing set...\n",
      "2432/2626 [==========================>...] - ETA: 0s[INFO] loss=0.6787, accuracy: 56.5499%\n"
     ]
    }
   ],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels,\n",
    "\tbatch_size=128, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,\n",
    "\taccuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results #\n",
    "feedforward neural net 5160-1024-512-2, relu activations. trained on 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
